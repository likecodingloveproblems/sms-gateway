
## تعریف مساله
یک sms gateway طراحی کنید که به ۱۰۰،۰۰۰ کاربر سرویس ارایه نماید و روزانه ۱۰۰ میلیون sms را ارسال نمیاد.
100,000,000 RPD
1,158 RPS (AVG)
10,000 (Peak. it's assumed!)

## Gateway
وظیفه این سرویس ارایه یک REST API به مشتریان میباشد تا SMS های خود را از طریق ارسال نمایند.
طبق نیازسنجی اعلامی هیچ پیامکی بعد از اتمام موجودی کاربر نباید توسط کاربر دریافت شود لذا این سرویس باید درخواست کاهش موجودی را به سرویس Accounting ارسال نماید. و در صورت موفقیت فرایند را ادامه دهد.
سپس SMS را برای ارسال برای پردازش و تحویل به اپراتور درون صف قرار دهد.
و نیز برای ذخیره سازی SMSها در سرویس reporting پیام ها به صورت همزمان در صف دیگری برای این سرویس قرار میگیرند.
## Accounting

این بخش مسیولیت مدیریت موجودی حساب کاربر را دارد.
##### نکات مهم:
- کاربران باید بتوانند تمام موجودی حساب خود را استفاده نمایند.
- پس از اتمام موجودی نباید هیچ اس ام اس ای از کاربر دریافت شود.

برای اینکه این سرویس بتواند به صورت sync به API Gateway  پاسخ دهد. باید از روش های sync استفاده کرد مانند REST و gRPC از آن جهت که لازم است ارتباط بین این سوریس ها کارآمد و ارتباط بین دوسرویس داخلی میباشد gRPC پیشنهاد میشود.
برای ذخیره سازی مقدار بالانس حساب کاربر باید از سرویسی استفاده شود که تا ۱۰،۰۰۰ اپدیت در ثانیه را پشتیبانی کند. و از طرفی از این جهت که consistency موجودی حساب کاربر مهم میباشد و این دیتا ساختارمند است پیشنهاد میشود از یک دیتابیس رابطه همراه با یک لایه cache به صورت write through cache ‌استفاده شود، به این صورت که تمامی درخواست ها توسط لایه کش پاسخ داده میشود و تغییرات در بازه های زمانی مشخصی با دیتابیس رابطه ای sync میشود.
برای cache میتوان از redis استفاده کرد. که به راحتی تا 5000 عملیات درثانیه را با single instance پاسخ خواهد داد و میتوان از sharding برای scale کردن آن استفاده کرد.
برای دیتابیس رابطه میتوان از postgres استفاده کرد.
حجم کش:  برای ۱۰۰،۰۰۰ مشتری 6.1MB [[Accounting Cache storage usage.]] 
#### سوالات کلیدی
۱. چه مکانیزمی برای همگام سازی postgres با redis پیشنهاد میدهید.
میتوان صرفا مقدار بالانس را در redis نگه داشت و آن را بروز رسانی کرد. و کل مقادیر balance را با postgres در یک درخواست انجام داد که این مساله به راحتی قابل انجام میباشد. مشکل این پیاده سازی scalable نبودن آن میباشد و در صورتی که چندین cache از دیتای postgres داشته باشیم ممکن است dirty write داشته باشیم. اما این راه حل بسیار ساده میباشد.
برای حل مسایل میتوان در کنار نگه داشتن balance کاربر تغییرات اعمال شده به صورت تجمیع شده نیز نگه داشته شود و در هنگام بروز رسانی صرفا تغییرات به postgres اعمال شود، در این صورت مشکل dirty write و scalable بودن تعداد مشتریان برطرف میشود.
*در اینجا برای سادگی راه حل اول پیشنهاد میشود.*
۲. در صورت خطا در ارسال پیامک میبایست مبلغ کم شده به حساب کاربر برگشت داده شود.
میتوان از saga pattern استفاده کرد به این صورت که در هنگام دریافت SMS مبلغ مورد نظر به عنوان بدهی توسط کاربر در سیستم ثبت شود و از حساب کاربر کم شود. و درصورت ارسال موفق پیام بدهی به صورت نهایی تلقی شده و در صورت عدم موفقیت در ارسال پیامک، مبلغ مورد نظر به حساب کاربر برگشت داده شده و بدهی مورد نظر به صورت برگشت داده شده ثبت شود. در صورتی که درخواست بدهی تا مدت زمان مشخصی پردازش نشود مقدار آن به حساب کاربر برگشت داده شده و بدهی منقضی شده شود.
این طراحی به ما این قابلیت را میدهد تا مقدار دقیق کم شده و دلیل آن را به صورت کامل در اختیار کاربر قرار دهیم. اما پیچیدگی بیشتری دارد.
میتوان یک API برای کسر موجودی حساب کاربر و یک API برای افزایش موجودی حساب کاربر در اختیار مابقی سرویس های داخلی قرار داد و در هنگام ارسال SMS موجودی مورد نظر از حساب کاربر کسر و در صورت عدم موفقیت در ارسال این مبلغ به حساب کاربر برگشت داده شود. این API ساده تر میباشد.

## Scheduler
### تعریف مساله
به صورت کلی دو سطح سرویس در سیستم در نظر گرفته شده است.
۱. سوریس اکسپرس که تضمین زمان تحویل اس ام اس را دارد.
۲. سرویس معمولی که تضمین زمان تحویل را ندارد.
برای سرویس معمولی باید منابع را به صورت عادلانه بین مشتریان تقسیم شود، به این صورت که اگر یک مشتری با نرخ بسیار بالایی اس ام اس ارسال میکند، تمام منابع سیستم به ایشان اختصاص داده نشود و استفاده مابقی مشتریان مختل نشود.
این مساله به صورت بسیار عمیق در سیستم عامل مورد بررسی قرار گرفته است و دو رویکرد برای حل آن 
در اینجا ما به این مساله میپردازیم که منابع به صورت عادلانه بین کاربران تقسیم شود. به صورت که کلی دورویکرد برای حل این مساله پیشنهاد میشود.
۱. بهینه کردن میانگین زمان انجام تسک: 
این رویکرد را میتوان با Multi Level Feedback Queue پیاده سازی کرد. به این صورت که چندین صف با اولویت های مختلف در سیستم طراحی شده و بسته به اینکه مشتری به چه مقدار از منابع استفاده کرده تسک جدید مشتری به یکی از صفوف اختصاص پیدا میکند. در اینجا ممکن است مشکلاتی مانند starvation اتفاق بیفتد که باید تمامی تسک ها در بازه زمانی مشخصی به صف با اولویت بالا منتقل شوند.
۲. تخصیص منصفانه منابع:
منابع را بین مشتریان به صورتی منصفانه تقسیم کنیم.
این رویکرد بسیار ساده تر از رویکرد قبل میباشد. و میتواند به دو صورت قطعی و احتمالی طراحی و پیاده سازی شود به این صورت که بسته به اولویت کاربر نسبت احتمال تخصیص منابع به کاربر تعیین میشود. پیچیدگی این روش در تعیین درصد اختصاص منابع به مشتریان میباشد.

#### مساله اول: آیا سرویس ها به صورت جداگانه دیپلوی شوند؟
اولین سوال این هست که آیا سیستم طراحی شده منابع را بین سرویس ها(اکسپرس و نرمال) تقسیم کند یا سرویس ها به صورت جداگانه از هم عملیاتی شوند و منابع جداگانه ای داشته باشند.
##### راه حل اول: سرویس های جداگانه
 اکر سرویس ها به صورت جداگانه عملیاتی شوند. مساله تقسیم عادلانه منابع بین مشتریان در سرویس معمولی را میتوان به broker ها سپرد. و برای سرویس اکسپرس میبایست زیرساختی داشته باشیم که بتواند horizontal autoscale انجام دهد که برای این مساله میبایست پاد مورد نظر متریک مطلوب خود را اکپوز کند تا توسط orchestrator مورد استفاده قرار گیرد.
###### ایرادات 
پیچیدگی زیادی به زیرساخت اضافه خواهد شد.
و منابع سرویس ها نمیتواند بین هم تقسیم شود. البته در صورت استفاده از سرویس های ابری میتوان این مساله را توسط سرویس های ابری مدیریت کرد، بدین صورت که سرویس مورد نظر در صورت نیاز scale up  و scale down کند.
###### مزایا
کد بسیار ساده تر می شود. و عملا مساله توسط زیرساخت مدیریت خواهد شد.

##### راه حل دوم: تقسیم منابع بین سرویس های مختلف
در این راه حل مسیول تقسیم منابع ‌scheduler خواهد بود. و schedulerمنابع را بین سروبس های مختلف تقسیم خواهد کرد. باید بتوانیم به scheduler ای برسیم که به صورت stateless پیاده سازی شود.
در این صورت میتوان برای زیرساخت طراحی بسیار ساده ای را درنظر گرفت به این صورت که 

### راه حل انتخابی
از انجا که نمیخواهیم برای زیرساخت الزام به پیچیدگی داشته باشیم و بتوانیم با زیرساختی ساده نیاز های مساله را برطرف کنیم. راه حل دوم را انتخاب میکنیم.

*از آن جهت که بتوان کنترل بیشتری بر مدیریت منابع بین تسک ها داشت سعی میشود در هنگام consume توزیع انجام شود تا در زمان produce، با این روش مساله زیادی مانند rebalancing رو حذف میکنیم.

با توجه به اینکه redis streams برای این مساله انتخاب شده است. از ادبیات آن در این بخش استفاده خواهد شد. [[Message broker selection desicion]]

پیام های براساس سطح سرویس در صف های جداگانه ارسال خواهند شد.
سرویس اکسپرس: express stream
	*از ان جهت در یک صف ارسال میشوند که برای سرویس اکسپرس SLA لحاظ شده و لذا نیازی به لود بالانسینگ نمیباشد.*
سرویس معمولی: normal stream for each user
در یک چرخه نامحدود هر بار به صورت احتمالی یکی از سرویس های express و normal انتخاب میشود:
- در صورت انتخاب سرویس اکسپرس تعدادی پیام از صف خوانده شده و پردازش میشوند.
- در صورت انتخاب سرویس معمولی از تمام stream ها کاربران تعدادی پیام خوانده شده و پردازش میشوند که باعث میشود منابع به صورت عادلانه بین کاربران توزیع شود.

##### Probabilistic Proportional sharing
برای انتخاب سرویس در هر بار چرخه از روش probabilistic proportional sharing  استفاده شده است به این صورت که تلاش میشود delivery time پیام های سرویس ‌express روی 70% SLA نگه داشته شود.
برای این منظور میبایست احتمال انتخاب هر سرویس را بهینه کرد. در صورت نزدیک شدن به SLA برای مثال 90% SLA میتوان مقدار زیادی از منابع را به سرویس express اختصاص داد، لیکن از آن جهت که starvation اتفاق نیفتد بهتر است مقدار حداقلی (مانند 5% منابع) همچنان در اختیار سرویس نرمال قرار گیرد.
##### نکات پیاده سازی
- در صورت بروز مشکل در پردازش پیام بعد از retry آن پیام به Dead Letter Queue  ارسال میشود.
- برای جلوگیری از backpressure در scheduler میبایست worker ای طراحی شود تا تعداد مشخصی پیام را در لحظه پردازش کند و نیز صف محدودی داشته باشد تا حجم پیام های دریافتی کنترل شود.
- برای اینکه scheduler را بتوان اسکیل کرد نیاز است که این سرویس stateless باشد لذا برای ذخیره سازی delivery-time از redis استفاده شود.
- مقدار delivery time به صورت دوره ای باید بروز رسانی شود.

#### بهبود های آینده
- با توحه به اینکه تعداد صفوف ۱۰۰،۰۰۰ میباشد در حال حاضر دریافت پیام از تمام صفوف ممکن است اما این راه حل مقیاس پذیر نبوده و میتوان از load balancer ای نیز برای توزیع بار بین stream ها استفاده کرد. و تعداد محدودی از streamها را در هر لوپ اجرا کرد.
- صفوف سرویس معمولی میتوانند برای بعضی از کاربران بسیار طولانی شوند، میتوان مقداری از منابع را به صورت مداوم به صفوف طولانی احتصاص داد.

دیاگرام زیر میتوان دید خوبی به راه حل دهد.
[[Scheduler.canvas|Scheduler]]

## Reporting
این سرویس باید گزارش تمام اس ام اس های ارسالی را نگه داشته و در اختیار کاربر قرار دهد.
#### نیازمندی ها
- این سرویس به صورت روزانه ۱۰۰ میلیون insert و partial update را پوشش میدهد.
- برای read میخواهیم پیام ها را به ترتیب دریافت از مشتری در جدولی نمایش دهیم و پیجینیشن هم داشته باشیم.
- میخواهیم این سرویس به نسبت realtime باشد تا کاربر اگر خواست که وضعیت SMS هاش رو ببینه بتونه به خوبی دنبال کنه و گیج نشه فک کنم سیستم دریافت نکرده پیامکش رو

#### گزینه های پیشنهادی
1. Postgres:
	1. Good for row base reads with filtering and ordering efficient support with partitioning and indexing
	2. Support partial update effectively
	3. High write throughput
2. Clickhouse:
	1. Does not efficiently support partial updates
	2. Performance problems when loading the whole row
	3. *Is suitable for the scenarios that we want to generate reports with aggregation in time intervals.*
3. Cassandra:
	1. Does not support partial update efficiently
4. MongoDB:
	1. Very good for our usecase

#### راه حل
با توجه به اینکه در سیستم accounting نیز از postgres استفاده شده میتوان در این سرویس نیز از postgres استفاده کرد تا استک کوچیک نگه داشته بشه.
برای write میتونیم از تکنیک stashing استفاده کنیم به این شکل که write  ها و partial updateها در ی بازه زمانی کوتاه مثلا ۵ ثانیه batch شده و در یک query به دیتابیس منتقل شوند که میشود 25,000 row که این نرخ را به خوبی pos
tgres پشتیبانی میکند.
و برای read از partition(user_id, created_at) استفاده میشود که میتواند تاثیر به سزایی در کویری های read داشته باشد.
*نکته پیاده سازی: برای کویری های read میبایست تلاش شود تا کویری در یک پارتیشن اعمال شود. و برای pagination بهتر است به جای استفاده از offset از id و created-at استفاده شود تا postgres بتواند به راحتی به partition مورد نظر رسیده و براساس index  روی id به سطر مورد نظر برسد.*
[link](https://chatgpt.com/share/68849abb-3c68-800d-a396-3b2cc2f4c921)

## Operator
ممکنه که اپراتورهای مختلفی داشته باشیم که بهمون سرویس های مختلفی داشته باشن و بعضی از اپراتور ها سرویس هایی داشته باشن که SLA داره یا priority های مختلف رو ساپورت کنن. و به صورت کل بخواهیم بین اپراتور ها هم لودبالانس انجام بدیم.
اما در اینجا برای سادگی صرفا یک اپراتور در نظر گرفته شد.